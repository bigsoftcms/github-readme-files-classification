= Classification of GitHub readme files

This project aims to find the best method for GitHub readme files classification in the meaning of quality. It is being developed during SummerCamp 2016 organized by http://datalab.fit.cvut.cz/[Data Science Laboratory at FIT CTU].

IMPORTANT: This is work in progress and is very incomplete!

== Requirements

Development is being done using this setup:

* Node.js v4.4.7 (ES2015 features are used)
* Python v3.5.2 (Python 3 is used)
* Jupyter v4.1.0
* Anaconda 3 with Conda v4.1.11
* Bash v4.3.11

== Getting started

. Clone this repository
. Run `npm install`
. Install required conda packages: `conda install -c anaconda seaborn`, `conda install -c glemaitre imbalanced-learn`
. Obtain your own
 https://help.github.com/articles/creating-an-access-token-for-command-line-use/[GitHub API authorization token] and save it into `GITHUB_AUTH_TOKEN` file in root directory
. Download sample dataset using `scripts/download-sample-dataset.sh` (type number of repos to be downloaded)
. Extract raw features from sample dataset using `scripts/extract-sample-dataset.sh`
. Download manually classified dataset using `scripts/download-classified-dataset.sh`
. Extract raw features from manually classified dataset using `scripts/extract-classified-dataset.sh`
. Run all the three jupyter notebooks in following order: `Data preprocessing`, `Labeling`, `Classification`
. Classify a readme using `scripts/classify.sh` passing a readme file as the first argument.footnote:[Note that this script requires a python binary with bounded packages. You have to specify the path to this binary in the `classify.sh` script. The default one is: `~/anaconda3/bin/python`.]

== License

This project is MIT licensed. See `LICENSE.txt` for further info.
